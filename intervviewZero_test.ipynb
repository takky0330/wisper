{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "https://github.com/takky0330/wisper/blob/main/intervviewZero_test.ipynb",
      "authorship_tag": "ABX9TyM+H5pJh0lr17wzr4lg9aPS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takky0330/wisper/blob/main/intervviewZero_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install m3u8"
      ],
      "metadata": {
        "id": "cRGcsIobNapm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_oGHqinTJxz"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "#!pip install -U git+https://github.com/jianfch/stable-ts.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install moviepy"
      ],
      "metadata": {
        "id": "iLJk39Pl9X3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ffmpeg-python"
      ],
      "metadata": {
        "id": "MT_AwBERdCH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub"
      ],
      "metadata": {
        "id": "faua_Zz20kRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "#import stable_whisper\n",
        "import ffmpeg\n",
        "from pydub import AudioSegment\n",
        "import numpy as np\n",
        "import json, re, os\n",
        "from datetime import datetime\n",
        "import glob\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "from moviepy.editor import VideoFileClip, CompositeVideoClip\n",
        "from moviepy.editor import AudioFileClip, CompositeAudioClip, concatenate_audioclips\n",
        "from moviepy.audio.AudioClip import AudioArrayClip\n",
        "import m3u8"
      ],
      "metadata": {
        "id": "FBaUgrssTrus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp ./drive/MyDrive/IZ-2218確認５/*.* ./\n",
        "#!cp ./drive/MyDrive/IZ-2218確認４/*.* ./\n",
        "#!cp ./drive/MyDrive/IZ-2218確認３/*.* ./"
      ],
      "metadata": {
        "id": "8ZZr3sOuBEDU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_webm(path):\n",
        "    with open('./' + path) as f:\n",
        "        for _line in f:\n",
        "            if _line.rstrip()[-5:] == '.webm':\n",
        "                return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "YiH52CTdeaai"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_webm(input_file):\n",
        "    #!ffmpeg -allowed_extensions ALL -f hls -i ./drive/MyDrive/IZ-2218確認３/ee93aa2994411ebff28d459c4711228b_1731555758981__uid_s_907719631__uid_e_video.m3u8 -c:v copy -y ./ee93aa2994411ebff28d459c4711228b_1731555758981__uid_s_907719631__uid_e_video.webm\n",
        "    webm_tmp = '.'.join(input_file.split('.')[:-1]) + '.webm'\n",
        "    try:\n",
        "        (\n",
        "            ffmpeg\n",
        "            .input('./' + input_file, allowed_extensions='ALL')\n",
        "            .output(webm_tmp, vcodec=\"copy\")\n",
        "            .overwrite_output()\n",
        "            .run(capture_stderr=True, capture_stdout=True)\n",
        "        )\n",
        "        _clip = VideoFileClip(webm_tmp)\n",
        "    except ffmpeg.Error as e:\n",
        "        print(f\"{e.stderr.decode()}\")\n",
        "        print(f\"標準出力: {e.stdout.decode()}\")\n",
        "        _clip = None\n",
        "    return _clip, webm_tmp"
      ],
      "metadata": {
        "id": "9o52BsqOfiQV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_list(path):\n",
        "    video_path = f'{path}*_video.m3u8'\n",
        "    video_paths = glob.glob(video_path)\n",
        "    video_paths.sort()\n",
        "    return video_paths\n",
        "def get_audio_list(path):\n",
        "    audio_path = f'{path}*_audio.m3u8'\n",
        "    audio_paths = glob.glob(audio_path)\n",
        "    audio_paths.sort()\n",
        "    return audio_paths"
      ],
      "metadata": {
        "id": "4DqRD33Bh4yy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_unix_time(date_string):\n",
        "    year = int(date_string[:4])\n",
        "    month = int(date_string[4:6])\n",
        "    day = int(date_string[6:8])\n",
        "    hour = int(date_string[8:10])\n",
        "    minute = int(date_string[10:12])\n",
        "    second = int(date_string[12:14])\n",
        "    millisecond = int(date_string[14:])\n",
        "    dt = datetime(year, month, day, hour, minute, second)\n",
        "    unix_time = int(dt.timestamp()) * 1000 + millisecond\n",
        "    return unix_time"
      ],
      "metadata": {
        "id": "n6nhjzO-NbHc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_silent_segment(input_audio_path, output_audio_path, check=False):\n",
        "    m3u8_obj = m3u8.load(input_audio_path)\n",
        "    segments = m3u8_obj.segments\n",
        "\n",
        "    audio_clips = []\n",
        "    previous_end_time = 0  # 無音の計算用\n",
        "    duration = 0\n",
        "\n",
        "    for segment in segments:\n",
        "        segment_url = segment.uri\n",
        "        segment_duration = segment.duration\n",
        "        segment_start_time = conv_unix_time(segment.uri.split('_')[-1].split('.')[0])\n",
        "\n",
        "        audio = AudioFileClip(segment_url)\n",
        "\n",
        "        # 無音が必要なら追加\n",
        "        if  segment.media_sequence > 0 and previous_end_time < segment_start_time:\n",
        "            #print(segment.media_sequence, '無音', segment_start_time, ' > ', previous_end_time, (segment_start_time - previous_end_time) / 1000, flush=True)\n",
        "            silence_duration = (segment_start_time - previous_end_time) / 1000\n",
        "            silence = AudioArrayClip(np.zeros((int(silence_duration * audio.fps), 2)), fps=audio.fps)\n",
        "            audio_clips.append(silence)\n",
        "            duration += silence_duration\n",
        "            if check == True:\n",
        "                _check = True\n",
        "                break\n",
        "\n",
        "        if check == True:\n",
        "            if _check == True:\n",
        "                return True\n",
        "            else:\n",
        "                return False\n",
        "\n",
        "        previous_end_time = segment_start_time + int(segment_duration * 1000)\n",
        "\n",
        "        # 音声をリストに追加\n",
        "        audio_clips.append(audio)\n",
        "\n",
        "    # すべての音声を結合\n",
        "    final_audio = concatenate_audioclips(audio_clips)\n",
        "    return final_audio\n"
      ],
      "metadata": {
        "id": "smF5h4yTNa25"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_speaker_monitor(result, sorted, video_paths):\n",
        "    prog = re.compile('教えて|聞か|聞き|願い|ください|ですか(?!ね)|でしょうか(?!ね)|ましたか|されましたか|いつ頃')\n",
        "    character = {}\n",
        "    INT_COUNT = []\n",
        "    for c in range(len(result)):\n",
        "        INT_COUNT.append([0, 0, 0, ''])\n",
        "    for srt, end, txt, spk in sorted:\n",
        "        count = len(prog.findall(txt))\n",
        "        spk_no = int(spk.split('_')[-1])\n",
        "        INT_COUNT[spk_no][0] += 1\n",
        "        INT_COUNT[spk_no][3] = spk\n",
        "        if count > 0:\n",
        "            INT_COUNT[spk_no][1] += count\n",
        "    for c, cnt in enumerate(INT_COUNT):\n",
        "        INT_COUNT[c][2] = cnt[1] / cnt[0]\n",
        "    INT_COUNT.index(min(INT_COUNT))\n",
        "\n",
        "    rate = [c[2] for c in INT_COUNT]\n",
        "    min_index = rate.index(min(rate))\n",
        "\n",
        "    for i, intv in enumerate(INT_COUNT):\n",
        "        user_id = audio_paths[i].split('_')[-5]\n",
        "        if i == min_index:\n",
        "            character[intv[3]] = {'character': \"モニター\", 'user_id': user_id, 'video_path' : video_paths[i]}\n",
        "        else:\n",
        "            character[intv[3]] = {'character': \"インタビューア_\" + intv[3].split('_')[-1], 'user_id': user_id, 'video_path' : video_paths[i]}\n",
        "    return character"
      ],
      "metadata": {
        "id": "1TYp74Tq4LTm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = './'\n",
        "video_paths = get_video_list(path)\n",
        "audio_paths = get_audio_list(path)\n",
        "interview_video_name = '_'.join(video_paths[0].split('/')[1].split('_')[0: 2]) + '.mp4'\n",
        "interview_audio_name = '_'.join(video_paths[0].split('/')[1].split('_')[0: 2]) + '.wav'\n",
        "interview_json_name = '_'.join(video_paths[0].split('/')[1].split('_')[0: 2]) + '.json'"
      ],
      "metadata": {
        "id": "XT68uSsBMEwJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video = []\n",
        "for v, video_path in enumerate(video_paths):\n",
        "    _video, _path = conv_webm(video_path) if is_webm(video_path) else (VideoFileClip(video_path), None)\n",
        "    if _path is not None:\n",
        "        video_paths[v] = _path\n",
        "    video.append(_video)\n",
        "video_paths"
      ],
      "metadata": {
        "id": "p2r1n94mMKzy",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio = []\n",
        "wav_paths = []\n",
        "for audio_path in audio_paths:\n",
        "    wav_path = '.'.join(audio_path.split('.')[:-1]) + '.wav'\n",
        "    if add_silent_segment(input_audio_path, output_audio_path, check=True):\n",
        "        audio_tmp = add_silent_segment(audio_path, wav_path)\n",
        "        print(\"無音あり\")\n",
        "    else:\n",
        "        audio_tmp = AudioFileClip(audio_path)\n",
        "        print(\"無音なし\")\n",
        "    audio_tmp.write_audiofile(wav_path, ffmpeg_params=[\"-ac\", \"1\"])\n",
        "    print(f'duration : {audio_tmp.duration}')\n",
        "    audio.append(audio_tmp)\n",
        "    wav_paths.append(wav_path)\n",
        "print(audio)"
      ],
      "metadata": {
        "id": "3JW5DgVSK5AU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model('large')\n",
        "#model = stable_whisper.load_model('large')\n",
        "#stable_whisper.modify_model(model)"
      ],
      "metadata": {
        "id": "tQ_TEOh7swqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asr_result = []\n",
        "for wav_patn in wav_paths:\n",
        "    print(f'\\n---- {wav_patn} ----')\n",
        "    #_result = model.transcribe(wav_patn, verbose=True, fp16=False, language=\"ja\", word_timestamps=True)\n",
        "    _result = model.transcribe(wav_patn, verbose=True, fp16=False, language=\"ja\", word_timestamps=True, logprob_threshold=0, no_speech_threshold=0.4, compression_ratio_threshold=2.6)\n",
        "    asr_result.append(_result)"
      ],
      "metadata": {
        "id": "v-IhvxuSHL72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_seg = []\n",
        "for spk, res in enumerate(asr_result):\n",
        "    for seg in res['segments']:\n",
        "        _seg.append([seg['start'], seg['end'], seg['text'], f'speaker_{format(spk, \"02\") }'])\n",
        "#_seg = []\n",
        "#for spk, res in enumerate(asr_result):\n",
        "#    for seg in res.segments:\n",
        "#        _seg.append([seg.start, seg.end, seg.text, f'speaker_{format(spk, \"02\") }'])"
      ],
      "metadata": {
        "id": "e-ve0CjbIy0q"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segments_sorted = sorted(_seg, key=lambda x:(x[0], x[1]))"
      ],
      "metadata": {
        "id": "BhIidIwe7kwi"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "characters = get_speaker_monitor(asr_result, segments_sorted, video_paths)\n",
        "print(characters)"
      ],
      "metadata": {
        "id": "IhxE59xwwZx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "InterReview_json = {\"movie_name\": interview_video_name}\n",
        "speak_json = []\n",
        "for start, end, text, speaker in segments_sorted:\n",
        "    _speak = {\"start\": f'{start:.2f}s', \"end\": f'{end:.2f}s', 'speaker': characters[speaker]['character'], 'speak': text}\n",
        "    speak_json.append(_speak)\n",
        "InterReview_json['InterReview'] = speak_json\n",
        "\n",
        "with open('./' + interview_json_name, 'w', encoding='utf-8') as f:\n",
        "    json.dump(InterReview_json, f, indent=4, ensure_ascii=False)"
      ],
      "metadata": {
        "id": "Q3H660Ljx-XY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_part = ['']  * len(characters)\n",
        "cnt = 1\n",
        "for c, char in enumerate(characters):\n",
        "    if characters[char]['character'] == 'モニター':\n",
        "        #video_part[0] = video[c]\n",
        "        video_part[0] = characters[char]['video_path']\n",
        "    else:\n",
        "        #video_part[cnt] = video[c]\n",
        "        video_part[cnt] = characters[char]['video_path']\n",
        "        cnt += 1"
      ],
      "metadata": {
        "id": "lR1jYPl1XeNG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#w,h = moviesize = video_part[0].size\n",
        "main_w, main_h = moviesize = VideoFileClip(video_part[0]).size\n",
        "wipe_w = 128\n",
        "wipe_h = 72\n",
        "wipe_margin_right = 4\n",
        "wipe_margin_top = 4"
      ],
      "metadata": {
        "id": "A560gy3thpzF"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#################### moviepy は出力が遅いので ffmpeg-python を利用\n",
        "\n",
        "#comp_mp4 = [video_part[0]]\n",
        "#for v in range(len(video_part) - 1):\n",
        "#    _wipe = (video_part[v + 1].\n",
        "#            resize((wipe_w, wipe_h)).\n",
        "#            margin(top=wipe_margin_top, right=wipe_margin_right, opacity=0).\n",
        "#            set_pos((main_w - wipe_w - wipe_margin_right, wipe_h * 0 + wipe_margin_right * 1)) )\n",
        "#    comp_mp4.append(_wipe)"
      ],
      "metadata": {
        "id": "hnK4Qe3jb17_"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#################### moviepy は出力が遅いので ffmpeg-python を利用\n",
        "#audio_clip = AudioFileClip(interview_audio_name)\n",
        "\n",
        "#combined_clip = CompositeVideoClip(comp_mp4)\n",
        "#combined_clip = combined_clip.set_audio(audio_clip)\n",
        "\n",
        "#wav_clips = []\n",
        "#for w_path in wav_paths:\n",
        "#    print(w_path)\n",
        "#    wav_clip = AudioFileClip(w_path)\n",
        "#    wav_clip.set_fps(44100)\n",
        "#    wav_clips.append(wav_clip)\n",
        "#composite_audio = CompositeAudioClip(wav_clips)\n",
        "#composite_audio.write_audiofile('./' + interview_audio_name, ffmpeg_params=[\"-ac\", \"1\"])"
      ],
      "metadata": {
        "id": "B4hVkFNWoxwE"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#################### moviepy は出力が遅いので ffmpeg-python を利用\n",
        "\n",
        "#combined_clip.write_videofile(interview_vido_name, fps=30, audio_codec = 'aac')"
      ],
      "metadata": {
        "id": "KyqTxNMbc-Gx"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comp_wav = AudioSegment.from_file(wav_paths[0])\n",
        "for w in range(len(wav_paths) - 1):\n",
        "    orver_wav = AudioSegment.from_file(wav_paths[w + 1])\n",
        "    comp_wav = comp_wav.overlay(orver_wav, position=0)\n",
        "comp_wav.export(interview_audio_name, format=\"wav\")"
      ],
      "metadata": {
        "id": "KjcjvU_049HE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voice = ffmpeg.input(interview_audio_name)\n",
        "\n",
        "video_clip = []\n",
        "for part in video_part:\n",
        "    _clop = ffmpeg.input(part)\n",
        "    video_clip.append(_clop)\n",
        "\n",
        "sub_scaled = []\n",
        "for c, clip in enumerate(video_clip):\n",
        "    if c == 0: continue\n",
        "    _scaled = clip.filter('scale', wipe_w, wipe_h)\n",
        "    sub_scaled.append(_scaled)\n",
        "\n",
        "orverlay = []\n",
        "for s, scl in enumerate(sub_scaled):\n",
        "    if s == 0:\n",
        "        sub1 = video_clip[0]\n",
        "        sub1 = sub1.filter('fps', fps=24, round='up')\n",
        "    else:\n",
        "        sub1 = orverlay[s - 1]\n",
        "    sub2 = scl\n",
        "    _orverlay = ffmpeg.overlay(sub1, sub2, x=(main_w - wipe_w - wipe_margin_right), y=(wipe_h * s + wipe_margin_top * (s + 1)) )\n",
        "    orverlay.append(_orverlay)\n",
        "\n",
        "output = ffmpeg.output(\n",
        "    orverlay[len(orverlay) - 1], voice.audio,\n",
        "    interview_video_name,\n",
        "    vcodec='libx264', acodec='aac', audio_bitrate='192k', preset='fast'\n",
        ")\n",
        "\n",
        "output = output.overwrite_output()\n"
      ],
      "metadata": {
        "id": "_pfG_4F6Lvk1"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    ffmpeg.run(output, capture_stderr=True, capture_stdout=True)\n",
        "except ffmpeg.Error as e:\n",
        "    print(f\"標準エラー{e.stderr.decode()}\")\n",
        "    print(f\"標準出力: {e.stdout.decode()}\")"
      ],
      "metadata": {
        "id": "Q7yCG-fo5aS2"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# 入力映像と音声ファイルの設定\n",
        "main = ffmpeg.input('ee93aa2994411ebff28d459c4711228b_1731555758981__uid_s_907719631__uid_e_video.webm')\n",
        "sub1 = ffmpeg.input('ee93aa2994411ebff28d459c4711228b_1731555758981__uid_s_462504175__uid_e_video.m3u8')\n",
        "sub2 = ffmpeg.input('ee93aa2994411ebff28d459c4711228b_1731555758981__uid_s_369679075__uid_e_video.m3u8')\n",
        "audio = ffmpeg.input('ee93aa2994411ebff28d459c4711228b_1731555758981.wav')\n",
        "\n",
        "# サブ映像のリサイズ\n",
        "sub1_scaled = sub1.filter('scale', wipe_w, wipe_h)\n",
        "sub2_scaled = sub2.filter('scale', wipe_w, wipe_h)\n",
        "\n",
        "# サブ映像1を右下にオーバーレイ\n",
        "overlay1 = ffmpeg.overlay(main, sub1_scaled, x=(main_w - wipe_w - wipe_margin_right), y=(wipe_h * 0 + wipe_margin_top * (0 + 1)))\n",
        "\n",
        "# サブ映像2を左上にオーバーレイ\n",
        "overlay2 = ffmpeg.overlay(overlay1, sub2_scaled, x=(main_w - wipe_w - wipe_margin_right), y=(wipe_h * s + wipe_margin_top * (1 + 1)))\n",
        "\n",
        "# 映像ストリームを取得\n",
        "#video_stream = overlay2.video\n",
        "\n",
        "# メイン映像の音声ストリームを取得\n",
        "#main_audio = main.audio\n",
        "\n",
        "# 音声のミックス（メイン映像の音声と外部音声をミックス）\n",
        "#mixed_audio = ffmpeg.filter([main_audio, audio], 'amix', inputs=2, duration='longest')\n",
        "\n",
        "# 映像と音声を結合して出力\n",
        "output = ffmpeg.output(\n",
        "    overlay2, audio.audio,\n",
        "    interview_video_name,\n",
        "    vcodec='libx264', acodec='aac', audio_bitrate='192k', preset='fast'\n",
        ")\n",
        "output = output.overwrite_output()\n",
        "\n",
        "# 実行\n",
        "ffmpeg.run(output)\n",
        "'''"
      ],
      "metadata": {
        "id": "kXqb5LJzPnVS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "08374b7e-19d2-4674-b6f1-08bccc145192"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# 入力映像と音声ファイルの設定\\nmain = ffmpeg.input('ee93aa2994411ebff28d459c4711228b_1731555758981__uid_s_907719631__uid_e_video.webm')\\nsub1 = ffmpeg.input('ee93aa2994411ebff28d459c4711228b_1731555758981__uid_s_462504175__uid_e_video.m3u8')\\nsub2 = ffmpeg.input('ee93aa2994411ebff28d459c4711228b_1731555758981__uid_s_369679075__uid_e_video.m3u8')\\naudio = ffmpeg.input('ee93aa2994411ebff28d459c4711228b_1731555758981.wav')\\n\\n# サブ映像のリサイズ\\nsub1_scaled = sub1.filter('scale', wipe_w, wipe_h)\\nsub2_scaled = sub2.filter('scale', wipe_w, wipe_h)\\n\\n# サブ映像1を右下にオーバーレイ\\noverlay1 = ffmpeg.overlay(main, sub1_scaled, x=(main_w - wipe_w - wipe_margin_right), y=(wipe_h * 0 + wipe_margin_top * (0 + 1)))\\n\\n# サブ映像2を左上にオーバーレイ\\noverlay2 = ffmpeg.overlay(overlay1, sub2_scaled, x=(main_w - wipe_w - wipe_margin_right), y=(wipe_h * s + wipe_margin_top * (1 + 1)))\\n\\n# 映像ストリームを取得\\n#video_stream = overlay2.video\\n\\n# メイン映像の音声ストリームを取得\\n#main_audio = main.audio\\n\\n# 音声のミックス（メイン映像の音声と外部音声をミックス）\\n#mixed_audio = ffmpeg.filter([main_audio, audio], 'amix', inputs=2, duration='longest')\\n\\n# 映像と音声を結合して出力\\noutput = ffmpeg.output(\\n    overlay2, audio.audio,\\n    interview_video_name,\\n    vcodec='libx264', acodec='aac', audio_bitrate='192k', preset='fast'\\n)\\noutput = output.overwrite_output()\\n\\n# 実行\\nffmpeg.run(output)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ]
}