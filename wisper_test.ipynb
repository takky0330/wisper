{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbx0iy9k6KcRmIiuBSDp+T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takky0330/wisper/blob/main/wisper_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_oGHqinTJxz",
        "outputId": "1317720d-f894-44ef-c801-0b111a2c1f9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-qtd8elnr\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-qtd8elnr\n",
            "  Resolved https://github.com/openai/whisper.git to commit 279133e3107392276dc509148da1f41bfb532c7e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.4.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.5)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.3.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting triton>=2.0.0 (from openai-whisper==20231117)\n",
            "  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper==20231117) (3.16.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2024.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802823 sha256=2c187303f476bc10fef81ba6ecb33b976289371c80edaf710925603734a48fdb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0bw7l03p/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: triton, tiktoken, openai-whisper\n",
            "Successfully installed openai-whisper-20231117 tiktoken-0.7.0 triton-3.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import json, re"
      ],
      "metadata": {
        "id": "FBaUgrssTrus"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(\"small\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QjBu_ODTwRA",
        "outputId": "72f38590-8fa6-4ff7-ff52-fdbc7e5b4ca0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████| 461M/461M [00:04<00:00, 116MiB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.transcribe(\"./9d4fc932d442ef2ffb17d0a8086390e6_1725887318814_0.mp4\", verbose=True, fp16=False, language=\"ja\") #ファイル指定"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wc3OYeXGT3SC",
        "outputId": "0ba3cb82-6cd5-4248-c83b-e92ad7747dbd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:00.000 --> 00:10.000] どうもこんにちは\n",
            "[00:10.000 --> 00:12.000] ありがとうございます\n",
            "[00:12.000 --> 00:19.000] ごめん 記者の時間いただきましてどうもありがとうございます\n",
            "[00:20.000 --> 00:22.000] どうもいい\n",
            "[00:24.000 --> 00:29.000] では早速質問をさせていただきたいと思います\n",
            "[00:29.000 --> 00:31.000] ちょっとだけお願いします\n",
            "[00:31.000 --> 00:49.000] では早速なんですけれども\n",
            "[00:49.000 --> 00:55.000] まずフリーをどうでしたでしょうか\n",
            "[00:56.000 --> 01:02.000] 今ちょっと回線がフリーズして聞こえなかったんですけど\n",
            "[01:02.000 --> 01:07.000] フリーを導入されたのはいつ頃でしたでしょうか\n",
            "[01:07.000 --> 01:19.000] 今から6年前で2018年の4月ですね\n",
            "[01:19.000 --> 01:23.000] すごい そんな前からだったんですね\n",
            "[01:23.000 --> 01:25.000] はい\n",
            "[01:25.000 --> 01:31.000] その当時他の例えばクラウド会計のものとかって\n",
            "[01:31.000 --> 01:33.000] ご検討されましたでしょうか\n",
            "[01:33.000 --> 01:41.000] マネーフォアードとフリーとどっちにしようかなという話はちょっと\n",
            "[01:41.000 --> 01:44.000] 私の中だけでありましたけども\n",
            "[01:45.000 --> 01:53.000] フリーの方がどうも私はその会計に詳しい人間ではないので\n",
            "[01:53.000 --> 02:03.000] 初心者向きだという話がちょっとしまったのレビューでありましたので\n",
            "[02:03.000 --> 02:08.000] じゃあフリーの方いいかなと思ってフリーしました\n",
            "[02:09.000 --> 02:11.000] 少し出しました\n",
            "[02:11.000 --> 02:18.000] 価格とかはその時って検討されましたか企画というか\n",
            "[02:18.000 --> 02:25.000] あまり積極的に企画してないんですけど\n",
            "[02:25.000 --> 02:28.000] 一応フリーの方は\n",
            "[02:28.000 --> 02:30.000] いくらだったかな\n",
            "[02:30.000 --> 02:36.000] 1万2万弱という感じだったので\n",
            "[02:36.000 --> 02:41.000] それぐらいならいいかなと思ってそれにしました\n",
            "[02:43.000 --> 02:48.000] 2万弱というのは月月月月ですか\n",
            "[02:48.000 --> 02:50.000] 年間です\n",
            "[02:50.000 --> 02:52.000] 年間で\n",
            "[02:53.000 --> 02:55.000] 少ししました\n",
            "[02:55.000 --> 03:01.000] これ今使われているのは\n",
            "[03:04.000 --> 03:07.000] ご職業が自営業ってことだったんですけども\n",
            "[03:07.000 --> 03:10.000] ご自身でやっていらっしゃるビジネスですかね\n",
            "[03:10.000 --> 03:12.000] そうですね\n",
            "[03:12.000 --> 03:18.000] 一応60歳で低年退職をしまして\n",
            "[03:19.000 --> 03:25.000] 会社に残るっていう選択肢もあったんですけど\n",
            "[03:25.000 --> 03:28.000] 給料が差があるのは分かってたので\n",
            "[03:28.000 --> 03:35.000] それぐらいだったら自分で個人事業の市になって\n",
            "[03:35.000 --> 03:47.000] 大体コンピュータシステム関係のサービス業を\n",
            "[03:47.000 --> 03:50.000] 会社でもやってましたので\n",
            "[03:50.000 --> 03:56.000] 同じような仕事を探せばいいかなと思ってやっております\n",
            "[03:56.000 --> 03:59.000] とりあえず\n",
            "[03:59.000 --> 04:02.000] それで一番のネックだったのが\n",
            "[04:02.000 --> 04:05.000] 個人事業の市になった時にネックだったのが\n",
            "[04:05.000 --> 04:08.000] 会計の農税ですよね\n",
            "[04:08.000 --> 04:13.000] 農税のこの辺の話っていうのが\n",
            "[04:14.000 --> 04:18.000] あまりほとんどやったことがなかったので\n",
            "[04:18.000 --> 04:23.000] 一応そういうクラウド会計ソフトがあれば\n",
            "[04:23.000 --> 04:28.000] その辺が楽できるかなと思って同意しました\n",
            "[04:31.000 --> 04:32.000] 生じたしました\n",
            "[04:32.000 --> 04:36.000] 現在ってこれあの法人統計されてらっしゃいますか\n",
            "[04:36.000 --> 04:38.000] してません\n",
            "[04:38.000 --> 04:41.000] 個人事業の市のままです\n",
            "[04:41.000 --> 04:43.000] 個人事業の市なんですね\n",
            "[04:43.000 --> 04:44.000] 消磁しました\n",
            "[04:44.000 --> 04:45.000] すいません\n",
            "[04:45.000 --> 04:51.000] 今回の面談の前提が法人だったので\n",
            "[04:51.000 --> 04:55.000] それも条件のところに入れていたんですけれども\n",
            "[04:55.000 --> 04:57.000] それは申し訳ない\n",
            "[04:57.000 --> 05:01.000] フリーもしくはMFのみ対象で導入して\n",
            "[05:01.000 --> 05:05.000] 使用しているユーザー募集ということだったので\n",
            "[05:05.000 --> 05:10.000] 法人縛りがあるとは知らなかったです\n",
            "[05:10.000 --> 05:11.000] すいません\n",
            "[05:11.000 --> 05:12.000] じゃあちょっと\n",
            "[05:12.000 --> 05:13.000] すいません\n",
            "[05:13.000 --> 05:15.000] 要件にあわないんだとは今回の話は\n",
            "[05:15.000 --> 05:18.000] キャンセルした方がよろしいでしょうか\n",
            "[05:18.000 --> 05:23.000] えっとこれ今からキャンセルってできるのかな\n",
            "[05:23.000 --> 05:24.000] わかんないです\n",
            "[05:24.000 --> 05:25.000] ごめんなさい\n",
            "[05:25.000 --> 05:26.000] ちょっと\n",
            "[05:26.000 --> 05:28.000] そうですか\n",
            "[05:28.000 --> 05:29.000] ちょっと\n",
            "[05:29.000 --> 05:32.000] どうしたらいいのかな\n",
            "[05:32.000 --> 05:33.000] とりあえずいいです\n",
            "[05:33.000 --> 05:37.000] 報酬がなくても構いませんので\n",
            "[05:37.000 --> 05:38.000] 申し訳れません\n",
            "[05:38.000 --> 05:43.000] そちらの方で納得いくまで\n",
            "[05:43.000 --> 05:44.000] ちょっとマクロミル\n",
            "[05:44.000 --> 05:46.000] ちょっとインタビューしていただいて\n",
            "[05:46.000 --> 05:48.000] そうしましたら\n",
            "[05:48.000 --> 05:51.000] ちょっと一旦ここで終わらせていただいて\n",
            "[05:51.000 --> 05:52.000] マクロミルの方に\n",
            "[05:52.000 --> 05:56.000] ここはちょっとキャンセルという形にできるか\n",
            "[05:56.000 --> 05:59.000] というのはちょっと交渉していますので\n",
            "[05:59.000 --> 06:00.000] はい\n",
            "[06:00.000 --> 06:01.000] はい\n",
            "[06:01.000 --> 06:02.000] 申し訳れません\n",
            "[06:02.000 --> 06:03.000] お時間いただいたところ\n",
            "[06:03.000 --> 06:04.000] いい\n",
            "[06:04.000 --> 06:06.000] こちらこそよく読んでます\n",
            "[06:06.000 --> 06:07.000] すいません\n",
            "[06:07.000 --> 06:08.000] とんでもないです\n",
            "[06:08.000 --> 06:09.000] すいません\n",
            "[06:09.000 --> 06:10.000] どうもありがとうございました\n",
            "[06:10.000 --> 06:11.000] ありがとうございます\n",
            "[06:11.000 --> 06:12.000] はい\n",
            "[06:12.000 --> 06:13.000] 失礼いたします\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "segments = result['segments']\n",
        "prog = re.compile('教えて|聞か|聞き|願い|ください|ですか|でしょうか|ましたか|されましたか|いつ頃')\n",
        "segment = []\n",
        "for seg in segments:\n",
        "  count = len(prog.findall(seg['text']))\n",
        "  if count > 0: print(seg['text'])\n",
        "  _seg = {'start': seg['start'], 'end': seg['end'], 'text': seg['text'], 'count': count}\n",
        "  segment.append(_seg)"
      ],
      "metadata": {
        "id": "aBB_x7vpf0az",
        "outputId": "6a5cb7e8-83a2-46ba-d544-2c01faf71411",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ちょっとだけお願いします\n",
            "まずフリーをどうでしたでしょうか\n",
            "フリーを導入されたのはいつ頃でしたでしょうか\n",
            "ご検討されましたでしょうか\n",
            "価格とかはその時って検討されましたか企画というか\n",
            "2万弱というのは月月月月ですか\n",
            "ご自身でやっていらっしゃるビジネスですかね\n",
            "キャンセルした方がよろしいでしょうか\n",
            "そうですか\n"
          ]
        }
      ]
    }
  ]
}