{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrrkwbMTjFYEocAoVmlcR/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takky0330/wisper/blob/main/wisper_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install moviepy pyannote-audio"
      ],
      "metadata": {
        "id": "lhxBgonIP5PW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from pyannote.audio import Pipeline, Audio\n",
        "from pyannote.core import Segment\n",
        "from pyannote.audio.pipelines.speaker_verification import PretrainedSpeakerEmbedding"
      ],
      "metadata": {
        "id": "CJeWPXJFQjlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install moviepy"
      ],
      "metadata": {
        "id": "iLJk39Pl9X3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip"
      ],
      "metadata": {
        "id": "FKtnurNW9mBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = \"./9d4fc932d442ef2ffb17d0a8086390e6_1725887318814_0.mp4\"\n",
        "audio_path = '.'.join(video_path.split('.')[:-1]) + '.wav'\n",
        "video = VideoFileClip(video_path)\n",
        "video.audio.write_audiofile(audio_path, ffmpeg_params=[\"-ac\", \"1\"])  #モノラルで出力"
      ],
      "metadata": {
        "id": "3JW5DgVSK5AU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_oGHqinTJxz"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import json, re"
      ],
      "metadata": {
        "id": "FBaUgrssTrus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(\"small\")"
      ],
      "metadata": {
        "id": "2QjBu_ODTwRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.transcribe(audio_path, verbose=True, fp16=False, language=\"ja\")"
      ],
      "metadata": {
        "id": "Wc3OYeXGT3SC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segments = result['segments']\n",
        "prog = re.compile('教えて|聞か|聞き|願い|ください|ですか|でしょうか|ましたか|されましたか|いつ頃')\n",
        "INTERVIEW = []\n",
        "for seg in segments:\n",
        "  count = len(prog.findall(seg['text']))\n",
        "  if count > 0: print(seg['text'])\n",
        "  _seg = {'start': seg['start'], 'end': seg['end'], 'text': seg['text'], 'count': count}\n",
        "  INTERVIEW.append(_seg)"
      ],
      "metadata": {
        "id": "aBB_x7vpf0az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segments = result['segments']\n",
        "embedding_model = PretrainedSpeakerEmbedding(\"speechbrain/spkrec-ecapa-voxceleb\", device='cpu')\n",
        "embeddings = np.zeros(shape=(len(segments), 192))\n",
        "\n",
        "duration = video.duration\n",
        "embeddings = []\n",
        "\n",
        "\n",
        "for i, segment in enumerate(segments):\n",
        "    audio = Audio()\n",
        "    start = segment[\"start\"]\n",
        "    end = min(duration, segment[\"end\"])\n",
        "    clip = Segment(start, end)\n",
        "    waveform, sample_rate = audio.crop(audio_path, clip)\n",
        "    print(waveform[0])\n",
        "    _enbed = embedding_model(waveform[None])\n",
        "    #print(_enbed[0])\n",
        "    embeddings.append(_enbed[0])\n",
        "\n",
        "embeddings = np.nan_to_num(embeddings)\n"
      ],
      "metadata": {
        "id": "RJG9GjQwudiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "speaker_count = 2"
      ],
      "metadata": {
        "id": "R0L5jb5VJQo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings)\n",
        "embeddings.shape"
      ],
      "metadata": {
        "id": "Hql5EsVeJx0-",
        "outputId": "8fd4033f-e104-42d0-b547-e5834e6cfe82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(96, 192)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clustering = AgglomerativeClustering(speaker_count).fit(embeddings)"
      ],
      "metadata": {
        "id": "Q6yQZfN-JbBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_segments = []\n",
        "for label, segment in zip(clustering.labels_, result[\"segments\"]):\n",
        "    labeled_segments.append((label, segment[\"start\"], segment[\"text\"]))\n",
        "\n",
        "interivew = []\n",
        "print(INTERVIEW)\n",
        "for s, (speaker, _, text) in enumerate(labeled_segments):\n",
        "    stime = INTERVIEW[s][\"start\"]\n",
        "    interivew.append(f\"話者{speaker + 1} :  {stime} 〜 : 「{text}」\")"
      ],
      "metadata": {
        "id": "PN2Y1ZHfMhNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for speek in interivew:\n",
        "  print(speek)"
      ],
      "metadata": {
        "id": "scndYnR8Mqv1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}