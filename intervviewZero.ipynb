{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "https://github.com/takky0330/wisper/blob/main/intervviewZero.ipynb",
      "authorship_tag": "ABX9TyPGpmVA1CWjSXBq7QgRVP/h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takky0330/wisper/blob/main/intervviewZero.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_oGHqinTJxz"
      },
      "outputs": [],
      "source": [
        "#!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install -U git+https://github.com/jianfch/stable-ts.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install moviepy"
      ],
      "metadata": {
        "id": "iLJk39Pl9X3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ffmpeg-python"
      ],
      "metadata": {
        "id": "MT_AwBERdCH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub"
      ],
      "metadata": {
        "id": "faua_Zz20kRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import whisper\n",
        "import stable_whisper\n",
        "import ffmpeg\n",
        "from pydub import AudioSegment\n",
        "import numpy as np\n",
        "import json, re, os\n",
        "import glob\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "from moviepy.editor import VideoFileClip, CompositeVideoClip\n",
        "from moviepy.editor import AudioFileClip, CompositeAudioClip"
      ],
      "metadata": {
        "id": "FBaUgrssTrus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!cp ./drive/MyDrive/IZ-2218確認４/*.* ./\n",
        "!cp ./drive/MyDrive/IZ-2218確認３/*.* ./"
      ],
      "metadata": {
        "id": "8ZZr3sOuBEDU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_webm(path):\n",
        "    with open('./' + path) as f:\n",
        "        for _line in f:\n",
        "            if _line.rstrip()[-5:] == '.webm':\n",
        "                return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "YiH52CTdeaai"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_webm(input_file):\n",
        "    #!ffmpeg -allowed_extensions ALL -f hls -i ./drive/MyDrive/IZ-2218確認３/ee93aa2994411ebff28d459c4711228b_1731555758981__uid_s_907719631__uid_e_video.m3u8 -c:v copy -y ./ee93aa2994411ebff28d459c4711228b_1731555758981__uid_s_907719631__uid_e_video.webm\n",
        "    webm_tmp = '.'.join(input_file.split('.')[:-1]) + '.webm'\n",
        "    try:\n",
        "        (\n",
        "            ffmpeg\n",
        "            .input('./' + input_file, allowed_extensions='ALL')\n",
        "            .output(webm_tmp, vcodec=\"copy\")\n",
        "            .overwrite_output()\n",
        "            .run(capture_stderr=True, capture_stdout=True)\n",
        "        )\n",
        "        _clip = VideoFileClip(webm_tmp)\n",
        "    except ffmpeg.Error as e:\n",
        "        print(f\"{e.stderr.decode()}\")\n",
        "        print(f\"標準出力: {e.stdout.decode()}\")\n",
        "        _clip = None\n",
        "    return _clip, webm_tmp"
      ],
      "metadata": {
        "id": "9o52BsqOfiQV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_list(path):\n",
        "    video_path = f'{path}*_video.m3u8'\n",
        "    video_paths = glob.glob(video_path)\n",
        "    video_paths.sort()\n",
        "    return video_paths\n",
        "def get_audio_list(path):\n",
        "    audio_path = f'{path}*_audio.m3u8'\n",
        "    audio_paths = glob.glob(audio_path)\n",
        "    audio_paths.sort()\n",
        "    return audio_paths"
      ],
      "metadata": {
        "id": "4DqRD33Bh4yy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_speaker_monitor(result, sorted, video_paths):\n",
        "    prog = re.compile('教えて|聞か|聞き|願い|ください|ですか(?!ね)|でしょうか(?!ね)|ましたか|されましたか|いつ頃')\n",
        "    character = {}\n",
        "    INT_COUNT = []\n",
        "    for c in range(len(result)):\n",
        "        INT_COUNT.append([0, 0, 0, ''])\n",
        "    for srt, end, txt, spk in sorted:\n",
        "        count = len(prog.findall(txt))\n",
        "        spk_no = int(spk.split('_')[-1])\n",
        "        INT_COUNT[spk_no][0] += 1\n",
        "        INT_COUNT[spk_no][3] = spk\n",
        "        if count > 0:\n",
        "            INT_COUNT[spk_no][1] += count\n",
        "    for c, cnt in enumerate(INT_COUNT):\n",
        "        INT_COUNT[c][2] = cnt[1] / cnt[0]\n",
        "    INT_COUNT.index(min(INT_COUNT))\n",
        "\n",
        "    rate = [c[2] for c in INT_COUNT]\n",
        "    min_index = rate.index(min(rate))\n",
        "\n",
        "    for i, intv in enumerate(INT_COUNT):\n",
        "        user_id = audio_paths[i].split('_')[-5]\n",
        "        if i == min_index:\n",
        "            character[intv[3]] = {'character': \"モニター\", 'user_id': user_id, 'video_path' : video_paths[i]}\n",
        "        else:\n",
        "            character[intv[3]] = {'character': \"インタビューア_\" + intv[3].split('_')[-1], 'user_id': user_id, 'video_path' : video_paths[i]}\n",
        "    return character"
      ],
      "metadata": {
        "id": "1TYp74Tq4LTm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = './'\n",
        "video_paths = get_video_list(path)\n",
        "audio_paths = get_audio_list(path)\n",
        "interview_video_name = '_'.join(video_paths[0].split('/')[1].split('_')[0: 2]) + '.mp4'\n",
        "interview_audio_name = '_'.join(video_paths[0].split('/')[1].split('_')[0: 2]) + '.wav'\n",
        "interview_json_name = '_'.join(video_paths[0].split('/')[1].split('_')[0: 2]) + '.json'"
      ],
      "metadata": {
        "id": "XT68uSsBMEwJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video = []\n",
        "for v, video_path in enumerate(video_paths):\n",
        "    _video, _path = conv_webm(video_path) if is_webm(video_path) else (VideoFileClip(video_path), None)\n",
        "    if _path is not None:\n",
        "        video_paths[v] = _path\n",
        "    video.append(_video)\n",
        "video_paths"
      ],
      "metadata": {
        "id": "p2r1n94mMKzy",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio = []\n",
        "wav_paths = []\n",
        "for audio_path in audio_paths:\n",
        "    wav_path = '.'.join(audio_path.split('.')[:-1]) + '.wav'\n",
        "    audio_tmp = AudioFileClip(audio_path)\n",
        "    audio_tmp.write_audiofile(wav_path, ffmpeg_params=[\"-ac\", \"1\"])\n",
        "    audio.append(audio_tmp)\n",
        "    wav_paths.append(wav_path)\n",
        "print(audio)"
      ],
      "metadata": {
        "id": "3JW5DgVSK5AU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = stable_whisper.load_model('large')\n",
        "stable_whisper.modify_model(model)"
      ],
      "metadata": {
        "id": "tQ_TEOh7swqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asr_result = []\n",
        "for wav_patn in wav_paths:\n",
        "    print(f'\\n---- {wav_patn} ----')\n",
        "    _result = model.transcribe(wav_patn, verbose=True, fp16=False, language=\"ja\", word_timestamps=True)\n",
        "    asr_result.append(_result)"
      ],
      "metadata": {
        "id": "v-IhvxuSHL72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_seg = []\n",
        "for spk, res in enumerate(asr_result):\n",
        "    for seg in res.segments:\n",
        "        _seg.append([seg.start, seg.end, seg.text, f'speaker_{format(spk, \"02\") }'])"
      ],
      "metadata": {
        "id": "e-ve0CjbIy0q"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segments_sorted = sorted(_seg, key=lambda x:(x[0], x[1]))"
      ],
      "metadata": {
        "id": "BhIidIwe7kwi"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "characters = get_speaker_monitor(asr_result, segments_sorted, video_paths)\n",
        "print(characters)"
      ],
      "metadata": {
        "id": "IhxE59xwwZx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "InterReview_json = {\"movie_name\": interview_video_name}\n",
        "speak_json = []\n",
        "for start, end, text, speaker in segments_sorted:\n",
        "    _speak = {\"start\": f'{start:.2f}s', \"end\": f'{end:.2f}s', 'speaker': characters[speaker]['character'], 'speak': text}\n",
        "    speak_json.append(_speak)\n",
        "InterReview_json['InterReview'] = speak_json\n",
        "\n",
        "with open('./' + interview_json_name, 'w', encoding='utf-8') as f:\n",
        "    json.dump(InterReview_json, f, indent=4, ensure_ascii=False)"
      ],
      "metadata": {
        "id": "Q3H660Ljx-XY"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_part = ['']  * len(characters)\n",
        "cnt = 1\n",
        "for c, char in enumerate(characters):\n",
        "    if characters[char]['character'] == 'モニター':\n",
        "        #video_part[0] = video[c]\n",
        "        video_part[0] = characters[char]['video_path']\n",
        "    else:\n",
        "        #video_part[cnt] = video[c]\n",
        "        video_part[cnt] = characters[char]['video_path']\n",
        "        cnt += 1"
      ],
      "metadata": {
        "id": "lR1jYPl1XeNG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#w,h = moviesize = video_part[0].size\n",
        "main_w, main_h = moviesize = VideoFileClip(video_part[0]).size\n",
        "wipe_w = 128\n",
        "wipe_h = 72\n",
        "wipe_margin_right = 4\n",
        "wipe_margin_top = 4"
      ],
      "metadata": {
        "id": "A560gy3thpzF"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#################### moviepy は出力が遅いので ffmpeg-python を利用\n",
        "\n",
        "#comp_mp4 = [video_part[0]]\n",
        "#for v in range(len(video_part) - 1):\n",
        "#    _wipe = (video_part[v + 1].\n",
        "#            resize((wipe_w, wipe_h)).\n",
        "#            margin(top=wipe_margin_top, right=wipe_margin_right, opacity=0).\n",
        "#            set_pos((main_w - wipe_w - wipe_margin_right, wipe_h * 0 + wipe_margin_right * 1)) )\n",
        "#    comp_mp4.append(_wipe)"
      ],
      "metadata": {
        "id": "hnK4Qe3jb17_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#################### moviepy は出力が遅いので ffmpeg-python を利用\n",
        "\n",
        "#combined_clip = CompositeVideoClip(comp_mp4)\n",
        "#combined_clip = combined_clip.set_audio(audio_clip)\n",
        "\n",
        "#wav_clips = []\n",
        "#for w_path in wav_paths:\n",
        "#    print(w_path)\n",
        "#    wav_clip = AudioFileClip(w_path)\n",
        "#    wav_clip.set_fps(44100)\n",
        "#    wav_clips.append(wav_clip)\n",
        "#composite_audio = CompositeAudioClip(wav_clips)\n",
        "#composite_audio.write_audiofile('./' + interview_audio_name, ffmpeg_params=[\"-ac\", \"1\"])"
      ],
      "metadata": {
        "id": "B4hVkFNWoxwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#################### moviepy は出力が遅いので ffmpeg-python を利用\n",
        "\n",
        "#combined_clip.write_videofile(interview_vido_name, fps=30, audio_codec = 'aac')"
      ],
      "metadata": {
        "id": "KyqTxNMbc-Gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comp_wav = AudioSegment.from_file(wav_paths[0])\n",
        "for w in range(len(wav_paths) - 1):\n",
        "    orver_wav = AudioSegment.from_file(wav_paths[w + 1])\n",
        "    comp_wav = comp_wav.overlay(orver_wav, position=0)\n",
        "comp_wav.export(interview_audio_name, format=\"wav\")"
      ],
      "metadata": {
        "id": "KjcjvU_049HE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_clip = AudioFileClip(interview_audio_name)"
      ],
      "metadata": {
        "id": "uXlJ1KUM6P76"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voice = ffmpeg.input(interview_audio_name)\n",
        "\n",
        "video_clip = []\n",
        "for part in video_part:\n",
        "    _clop = ffmpeg.input(part)\n",
        "    video_clip.append(_clop)\n",
        "\n",
        "sub_scaled = []\n",
        "for c, clip in enumerate(video_clip):\n",
        "    if c == 0: continue\n",
        "    _scaled = clip.filter('scale', wipe_w, wipe_h)\n",
        "    sub_scaled.append(_scaled)\n",
        "\n",
        "orverlay = []\n",
        "for s, scl in enumerate(sub_scaled):\n",
        "    if s == 0:\n",
        "        sub1 = video_clip[0]\n",
        "    else:\n",
        "        sub1 = orverlay[s - 1]\n",
        "    sub2 = scl\n",
        "    _orverlay = ffmpeg.overlay(sub1, sub2, x=(main_w - wipe_w - wipe_margin_right), y=(wipe_h * s + wipe_margin_top * (s + 1)) )\n",
        "    orverlay.append(_orverlay)\n",
        "\n",
        "output = ffmpeg.output(\n",
        "    orverlay[len(orverlay) - 1], voice.audio,\n",
        "    interview_video_name,\n",
        "    vcodec='libx264', acodec='aac', audio_bitrate='192k', preset='fast'\n",
        ")\n",
        "\n",
        "output = output.overwrite_output()\n",
        "\n",
        "try:\n",
        "    ffmpeg.run(output, capture_stderr=True, capture_stdout=True)\n",
        "except ffmpeg.Error as e:\n",
        "    print(f\"標準エラー{e.stderr.decode()}\")\n",
        "    print(f\"標準出力: {e.stdout.decode()}\")"
      ],
      "metadata": {
        "id": "_pfG_4F6Lvk1"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# 入力映像と音声ファイルの設定\n",
        "main = ffmpeg.input('ee93aa2994411ebff28d459c4711228b_1731555758981__uid_s_907719631__uid_e_video.webm')\n",
        "sub1 = ffmpeg.input('ee93aa2994411ebff28d459c4711228b_1731555758981__uid_s_462504175__uid_e_video.m3u8')\n",
        "sub2 = ffmpeg.input('ee93aa2994411ebff28d459c4711228b_1731555758981__uid_s_369679075__uid_e_video.m3u8')\n",
        "audio = ffmpeg.input('ee93aa2994411ebff28d459c4711228b_1731555758981.wav')\n",
        "\n",
        "# サブ映像のリサイズ\n",
        "sub1_scaled = sub1.filter('scale', wipe_w, wipe_h)\n",
        "sub2_scaled = sub2.filter('scale', wipe_w, wipe_h)\n",
        "\n",
        "# サブ映像1を右下にオーバーレイ\n",
        "overlay1 = ffmpeg.overlay(main, sub1_scaled, x=(main_w - wipe_w - wipe_margin_right), y=(wipe_h * 0 + wipe_margin_top * (0 + 1)))\n",
        "\n",
        "# サブ映像2を左上にオーバーレイ\n",
        "overlay2 = ffmpeg.overlay(overlay1, sub2_scaled, x=(main_w - wipe_w - wipe_margin_right), y=(wipe_h * s + wipe_margin_top * (1 + 1)))\n",
        "\n",
        "# 映像ストリームを取得\n",
        "#video_stream = overlay2.video\n",
        "\n",
        "# メイン映像の音声ストリームを取得\n",
        "#main_audio = main.audio\n",
        "\n",
        "# 音声のミックス（メイン映像の音声と外部音声をミックス）\n",
        "#mixed_audio = ffmpeg.filter([main_audio, audio], 'amix', inputs=2, duration='longest')\n",
        "\n",
        "# 映像と音声を結合して出力\n",
        "output = ffmpeg.output(\n",
        "    overlay2, audio.audio,\n",
        "    interview_video_name,\n",
        "    vcodec='libx264', acodec='aac', audio_bitrate='192k', preset='fast'\n",
        ")\n",
        "output = output.overwrite_output()\n",
        "\n",
        "# 実行\n",
        "ffmpeg.run(output)\n",
        "'''"
      ],
      "metadata": {
        "id": "kXqb5LJzPnVS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}