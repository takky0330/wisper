{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "https://github.com/takky0330/wisper/blob/main/intervviewZero.ipynb",
      "authorship_tag": "ABX9TyN1hvgp3u+ivysgw8atSYv7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takky0330/wisper/blob/main/intervviewZero.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_oGHqinTJxz"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install moviepy"
      ],
      "metadata": {
        "id": "iLJk39Pl9X3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ffmpeg-python"
      ],
      "metadata": {
        "id": "MT_AwBERdCH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import ffmpeg\n",
        "import numpy as np\n",
        "import json, re, os\n",
        "import glob\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "from moviepy.editor import VideoFileClip\n",
        "from moviepy.editor import AudioFileClip"
      ],
      "metadata": {
        "id": "FBaUgrssTrus"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp ./drive/MyDrive/IZ-2218確認３/*.* ./"
      ],
      "metadata": {
        "id": "8ZZr3sOuBEDU"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_webm(path):\n",
        "    with open('./' + path) as f:\n",
        "        for _line in f:\n",
        "            if _line.rstrip()[-5:] == '.webm':\n",
        "                return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "YiH52CTdeaai"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_webm(input_file):\n",
        "    #!ffmpeg -allowed_extensions ALL -f hls -i ./drive/MyDrive/IZ-2218確認３/ee93aa2994411ebff28d459c4711228b_1731555758981__uid_s_907719631__uid_e_video.m3u8 -c:v copy -y ./ee93aa2994411ebff28d459c4711228b_1731555758981__uid_s_907719631__uid_e_video.webm\n",
        "    webm_tmp = \"./video_tmp.webm\"\n",
        "    try:\n",
        "        (\n",
        "            ffmpeg\n",
        "            .input('./' + input_file, allowed_extensions='ALL')\n",
        "            .output(webm_tmp, vcodec=\"copy\")\n",
        "            .overwrite_output()\n",
        "            .run(capture_stderr=True, capture_stdout=True)\n",
        "        )\n",
        "        _clip = VideoFileClip(webm_tmp)\n",
        "    except ffmpeg.Error as e:\n",
        "        #print(f\"{e.stderr.decode()}\")\n",
        "        #print(f\"標準出力: {e.stdout.decode()}\")\n",
        "        _clip = None\n",
        "    return _clip"
      ],
      "metadata": {
        "id": "9o52BsqOfiQV"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_list(path):\n",
        "    video_path = f'{path}*_video.m3u8'\n",
        "    video_paths = glob.glob(video_path)\n",
        "    video_paths.sort()\n",
        "    return video_paths\n",
        "def get_audio_list(path):\n",
        "    audio_path = f'{path}*_audio.m3u8'\n",
        "    audio_paths = glob.glob(audio_path)\n",
        "    audio_paths.sort()\n",
        "    return audio_paths"
      ],
      "metadata": {
        "id": "4DqRD33Bh4yy"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = './'\n",
        "video_paths = get_video_list(path)\n",
        "audio_paths = get_audio_list(path)"
      ],
      "metadata": {
        "id": "XT68uSsBMEwJ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video = []\n",
        "for video_path in video_paths:\n",
        "    _video = conv_webm(video_path) if is_webm(video_path) else VideoFileClip(video_path)\n",
        "    video.append(_video)\n",
        "print(video)"
      ],
      "metadata": {
        "id": "p2r1n94mMKzy",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio = []\n",
        "wav_paths = []\n",
        "for audio_path in audio_paths:\n",
        "    wav_path = '.'.join(audio_path.split('.')[:-1]) + '.wav'\n",
        "    audio_tmp = AudioFileClip(audio_path)\n",
        "    audio_tmp.write_audiofile(wav_path, ffmpeg_params=[\"-ac\", \"1\"])\n",
        "    audio.append(audio_tmp)\n",
        "    wav_paths.append(wav_path)\n",
        "print(audio)"
      ],
      "metadata": {
        "id": "3JW5DgVSK5AU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YyZDL6H4Nl7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(\"large\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ_TEOh7swqx",
        "outputId": "6f521d68-7a56-4120-998f-0e0c0b3ff401"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████| 2.88G/2.88G [00:19<00:00, 155MiB/s]\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "asr_result = []\n",
        "for wav_patn in wav_paths:\n",
        "    print(f'---- {wav_patn} ----')\n",
        "    _result = model.transcribe(wav_patn, verbose=True, fp16=False, language=\"ja\", word_timestamps=True)\n",
        "    asr_result.append(_result)"
      ],
      "metadata": {
        "id": "v-IhvxuSHL72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "du7yMlxqsi-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "whisper_result = {}\n",
        "whisper_segment = []\n",
        "for asr in asr_result['segments']:\n",
        "    if asr['end'] - asr['start'] >= 0.6 and len(asr['text']) >= 2:\n",
        "        asr['text'] += '。'\n",
        "        whisper_segment.append(asr)\n",
        "whisper_result['segments'] = whisper_segment"
      ],
      "metadata": {
        "id": "HI_bYFi2kFcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "whisper_result"
      ],
      "metadata": {
        "id": "Zq59lbJNnJ0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#speaker_count = 2\n",
        "speaker_count = 3\n",
        "\n",
        "import torch\n",
        "pipeline.to(torch.device(\"cuda\"))\n",
        "diarization_result = pipeline(audio_path, num_speakers=speaker_count)\n",
        "#diarization_result = pipeline(audio_path, min_speakers=2, max_speakers=5)"
      ],
      "metadata": {
        "id": "4FVUQIrkXKEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diarization_result"
      ],
      "metadata": {
        "id": "9RsGrxvMw-xN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#final_result = diarize_text(asr_result, diarization_result)\n",
        "final_result = diarize_text(whisper_result, diarization_result)"
      ],
      "metadata": {
        "id": "WETpYo84XUGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prog = re.compile('教えて|聞か|聞き|願い|ください|ですか|でしょうか|ましたか|されましたか|いつ頃')\n",
        "INTERVIEW = []\n",
        "INT_COUNT = []\n",
        "for seg, spk, sent in final_result:\n",
        "  if spk is None:\n",
        "    spk = INTERVIEW[-1]['spk']\n",
        "  count = len(prog.findall(sent))\n",
        "  spk_no = int(spk.split('_')[-1])\n",
        "  if count > 0: print(str(sent))\n",
        "  _seg = {'start': round(seg.start, 2), 'end': round(seg.end, 2), 'text': sent, 'count': count, 'spk': spk, 'spk_no': spk_no}\n",
        "  INTERVIEW.append(_seg)\n",
        "  INT_COUNT.append(int(spk[-1]))\n",
        "\n",
        "speaker_count = max(INT_COUNT) + 1\n",
        "\n",
        "speek = [0] * speaker_count\n",
        "for INT in INTERVIEW:\n",
        "    speek[INT[\"spk_no\"]] += INT[\"count\"]\n",
        "inteviewer_index = np.argmax(speek)\n",
        "monitor_index = np.argmin(speek)\n",
        "\n",
        "print(speek)\n",
        "print(f'インタービューア ： SPEAKER_0{inteviewer_index}')\n",
        "print(f'モニター　　　　 ： SPEAKER_0{monitor_index}')"
      ],
      "metadata": {
        "id": "g7vH5Jh0Qmgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for seg, spk, sent in final_result:\n",
        "    speeker_name = spk\n",
        "    #speeker_name =   'モニタ　　　　'\n",
        "    #if spk == 'SPEAKER_0' + str(inteviewer_index):\n",
        "    #  speeker_name = 'インタビューア'\n",
        "    line = f'{seg.start:.2f}s~{seg.end:.2f}s {speeker_name} {sent}'\n",
        "    print(line)"
      ],
      "metadata": {
        "id": "7s_fnLsNQj8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "InterReview_json = {\"movie_name\": video_name}\n",
        "speak_json = []\n",
        "for seg, spk, sent in final_result:\n",
        "    _speak = {\"start\": f'{seg.start:.2f}s', \"end\": f'{seg.end:.2f}s', 'speaker': spk, 'speak': sent}\n",
        "    speak_json.append(_speak)\n",
        "InterReview_json['InterReview'] = speak_json\n",
        "\n",
        "json_path = '.'.join(video_path.split('.')[:-1]) + '.json'\n",
        "with open(json_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(InterReview_json, f, indent=4, ensure_ascii=False)\n"
      ],
      "metadata": {
        "id": "Q3H660Ljx-XY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -alh ./"
      ],
      "metadata": {
        "id": "JVo964bKAgPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp ./InterviewZero_0_audio_mask.json ./drive/MyDrive"
      ],
      "metadata": {
        "id": "Reu1aUW8_iX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp ./InterviewZero_1_audio_mask.json ./drive/MyDrive"
      ],
      "metadata": {
        "id": "UUx_tPR-Brjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp ./InterviewZero_2_audio_mask.json ./drive/MyDrive"
      ],
      "metadata": {
        "id": "I5D_hrldBsLm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}